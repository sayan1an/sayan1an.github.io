<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Sayantan's Differentiable Indirection page">    <title>Efficient Graphics Representation with Differentiable Indirection</title>    
    <link rel="stylesheet" href="https://unpkg.com/purecss@1.0.1/build/pure-min.css" integrity="sha384-" crossorigin="anonymous">
    <link rel="stylesheet" href="css/layouts/side-menu.css">
    <link rel="stylesheet" href="https://unpkg.com/purecss@1.0.1/build/grids-responsive-min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
</head>
<body>

<div id="layout" class="pure-g">
    <div class="pure-u-1 pure-u-md-1-4"></div>
    <div id="main" class="pure-u-1 pure-u-md-2-4">
        <div class="header">
            <div class="pure-menu pure-menu-horizontal">
                <h1>Efficient Graphics Representation</h1>
                <h1>with Differentiable Indirection</h1>
                <h4 style="margin-top: 6px; text-align: center; font-size: medium;margin-bottom: 6px;">(In SIGGRAPH ASIA '23 Conference Proceedings)</h4>
            </div>
            <div class="pure-menu pure-menu-horizontal">
                <ul class="pure-menu-list">
                    <li class="pure-menu-item"><a href="menu2.html" class="pure-menu-link">Sayantan Datta</a></li>
                    <li class="pure-menu-item"><a href="" class="pure-menu-link">Carl Marshall</a></li>
                    <li class="pure-menu-item"><a href="https://www.cim.mcgill.ca/~derek/" class="pure-menu-link">Derek Nowrouzezahrai</a></li>
                    <li class="pure-menu-item"><a href="http://flycooler.com/" class="pure-menu-link">Zhao Dong</a></li>
                    <li class="pure-menu-item"><a href="" class="pure-menu-link">Zhengqin Li</a></li>
                </ul>
            </div>
            
        </div>

        <div class="content">
            
            <div>
                <video width="800"  style="margin-top: 10px;" autoplay loop playsinline muted>
                    <source src="images/din/collageN.mp4" type="video/mp4">
                </video>
                <p style="text-align:justify; margin-top: 0px;"> Applications of <i>Differentiable indirection</i> across graphics pipeline.  From left to right, texture compression, SDF representation, texture filtering and parametric shading, and radiance field compression. Go to <a href="#download">Downloads</a>.               
                </p>
            </div>

            <h2 class="content-subhead" style="margin-top: 10px;color:#001f3f;">Abstract</h2>
            <p style="text-align:justify;">We introduce <i>differentiable indirection</i> – a novel learned primitive that employs differentiable multi-scale lookup tables as an effective substitute for traditional compute and data operations across the graphics pipeline. We demonstrate its flexibility on a number of graphics tasks, i.e., geometric and image representation, texture mapping, shading, and radiance field representation. In all cases, differentiable indirection seamlessly integrates into existing architectures, trains rapidly, and yields both versatile and efficient results.</p>
            
            <h2 class="content-subhead" style="margin-top: 10px;color:#001f3f;">What is differentiable indirection?</h2>
            <div>
                <figure>
                    <img src="images/din/din.png" width="820" style ="position:relative; right:45px;"/>
                    <figcaption style="text-align:justify; width: 800px; position:relative; right:35px;" >Similar to a pointer indirection - we query a memory location that contains a pointer to a secondary location containing the final output. However, our pointer indirection is also differentiable, hence <i>Differentiable indirection</i>.</figcaption>
                </figure>
            </div>

            <h2 class="content-subhead" style="margin-top: 10px;color:#001f3f;">Why use differentiable indirection?</h2>
            <div>
                <figure>
                    <img src="images/din/equalPsnrGraphAn.png" width="700" style ="position:relative; right:-15px;"/>
                    <figcaption style="text-align:justify; width: 800px; position:relative; right:35px;" >Our technique is bandwidth, compute, and space efficient. MLP layers are computationally expensive in both FLOPs and memory bandwidth while single level memory grids (LUTs) incurs large parameter cost. <i>Differentiable
                        indirection</i> strikes a balance across these criteria and useful for a variety of data compression and compute representation tasks. The plot compares relative resource utilization of various
                        architectures on a log scale at equal quality approximation of Isotropic GGX. Our technique is flexible and highly modular, making it useful for a variety of multi-modal representation task.</figcaption>
                </figure>
            </div>
            
            <h2 class="content-subhead" style="margin-top: 10px; color:#001f3f;">Video description</h2>
            <div>
            <iframe style="border-radius: 0px;" width="800px" height="450" src="https://www.youtube.com/embed/VKMoTSGY4N4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
            </div>        

            <h2 class="content-subhead" style="margin-top: 10px; color:#001f3f;">Results & comparision</h2>
            <div class="juxtapose">
                <img src="images/din/sdf/oursPiano.jpg" data-label="Ours (24 MB)"/>
                <img src="images/din/sdf/refPiano.jpg" data-label="Reference (12 GB)"/>
            </div>
            <p style="text-align:justify; width: 800px; position:relative; right:0px;" >SDF representation using <i>differentiable indirection</i> compared with reference Kd-Tree with 1B surface sample points. SDF to mesh reconstruction for visualization using marching-cubes algorithm. </p>
            <div class="juxtapose">
                <img src="images/din/sdf/oursPiano.jpg" data-label="Ours (24 MB)"/>
                <img src="images/din/sdf/mrhePiano.jpg" data-label="MRHE (24 MB)"/>
            </div>
            <p style="text-align:justify; width: 800px; position:relative; right:0px;" >SDF representation using <i>differentiable indirection</i> compared with MRHE with 8-Levels (6 Desne + 2 Hash) + MLP (4-hidden layer 16 wide). SDF to mesh reconstruction for visualization using marching-cubes algorithm.</p>
            <div class="juxtapose">
                <img src="images/din/images/6x.jpg" data-label="Ours (6x)"/>
                <img src="images/din/images/ref.jpg" data-label="Reference (3K)"/>
            </div>
            <p style="text-align:justify; width: 800px; position:relative; right:0px;" >6x image compression using <i>differentiable indirection</i> compared with uncompressed 3K (1K x 3) reference.</p>
            <div class="juxtapose">
                <img src="images/din/images/12x.jpg" data-label="Ours (12x)"/>
                <img src="images/din/images/ref.jpg" data-label="Reference (3K)"/>
            </div>
            <p style="text-align:justify; width: 800px; position:relative; right:0px;" >12x image compression using <i>differentiable indirection</i> compared with uncompressed 3K (1K x 3) reference.</p>
            <div class="juxtapose">
                <img src="images/din/images/24x.jpg" data-label="Ours (24x)"/>
                <img src="images/din/images/ref.jpg" data-label="Reference (3K)"/>
            </div>
            <p style="text-align:justify; width: 800px; position:relative; right:0px;" >24x image compression using <i>differentiable indirection</i> compared with uncompressed 3K (1K x 3) reference.</p>
            <div class="juxtapose">
                <img src="images/din/images/48x.jpg" data-label="Ours (48x)"/>
                <img src="images/din/images/ref.jpg" data-label="Reference (3K)"/>
            </div>
            <p style="text-align:justify; width: 800px; position:relative; right:0px;" >48x image compression using <i>differentiable indirection</i> compared with uncompressed 3K (1K x 3) reference.</p>
            <div class="juxtapose">
                <img src="images/din/disney/Disney_ours.jpg" data-label="Ours (5 bilinear lookups + 41 FLOPs)"/>
                <img src="images/din/disney/Disney_ref.jpg" data-label="Reference (240+ FLOPs)"/>
            </div>
            <p style="text-align:justify; width: 800px; position:relative; right:0px;" >Disney BRDF approximation using <i>differentiable indirection</i> compared with analytic reference.</p>
            <div class="juxtapose">
                <img src="images/din/filtering/albedo/ours_12x.jpg" data-label="Ours (12x + Implicit filtering)"/>
                <img src="images/din/filtering/albedo/ref.jpg" data-label="Reference (Anisotropic filtering)"/>
            </div>
            <p style="text-align:justify; width: 800px; position:relative; right:0px;" >12x texture compression (Albedo) and filtering using <i>differentiable indirection</i> compared with uncompressed anisotropic (16spp) filtered textures. Our network uses pixel footprint information to generate appropriately filtered results.</p>
            <div class="juxtapose">
                <img src="images/din/filtering/albedo/ours_12x.jpg" data-label="Ours (12x + Implicit filtering)"/>
                <img src="images/din/filtering/albedo/astc_12x.jpg" data-label="ASTC (12x + Nearest filtering)"/>
            </div>
            <p style="text-align:justify; width: 800px; position:relative; right:0px;" >12x texture compression (Albedo) and filtering using <i>differentiable indirection</i> compared with 12x ASTC compressed nearest-neighbour sampled textures. Our network uses pixel footprint information to generate appropriately filtered results. However, unlike ASTC, our network can simultaneously compress and filter without any additional filtering hardware.</p>
            <div class="juxtapose">
                <img src="images/din/filtering/normal/normal_ours12x.jpg" data-label="Ours (12x + Implicit filtering)"/>
                <img src="images/din/filtering/normal/normal_ref.jpg" data-label="Reference (Anisotropic filtering)"/>
            </div>
            <p style="text-align:justify; width: 800px; position:relative; right:0px;" >12x normal-mapped texture compression and filtering using <i>differentiable indirection</i> compared with uncompressed anisotropic (16spp) filtered textures. Our network uses pixel footprint information to generate appropriately filtered results.</p>
            <div class="juxtapose">
                <img src="images/din/filtering/normal/normal_ours12x.jpg" data-label="Ours (12x + Implicit filtering)"/>
                <img src="images/din/filtering/normal/normal_astc12.jpg" data-label="ASTC (12x + Nearest filtering)"/>
            </div>
            <p style="text-align:justify; width: 800px; position:relative; right:0px;" >12x normal-mapped texture compression and filtering using <i>differentiable indirection</i> compared with 12x ASTC compressed nearest-neighbour sampled textures. Our network uses pixel footprint information to generate appropriately filtered results. However, unlike ASTC, our network can simultaneously compress and filter without any additional filtering hardware. Notice ASTC nearest-neighbour samples are much noisier at larger pixel-footprints due to aliasing, but our technique produces better filtered results at similar resource utilization.</p>
            <div class="juxtapose">
                <img src="images/din/shading/output_sh.jpg" data-label="Ours"/>
                <img src="images/din/shading/output_shRef.jpg" data-label="Reference"/>
            </div>
            <p style="text-align:justify; width: 800px; position:relative; right:0px;" >Combined shading (our Disney), and texture filtering (12x compressed albedo and normal maps) using <i>differentiable indirection</i> compared with uncompressd anisotropic textures and analytic Disney shading.</p>
            <div class="juxtapose">
                <img src="images/din/nerf/ours_low_comp10.jpg" data-label="Ours (89 MB)"/>
                <img src="images/din/nerf/ref_10.jpg" data-label="Reference (860 MB)"/>
            </div>
            <p style="text-align:justify; width: 800px; position:relative; right:0px;" >Compressed NeRF representation (89 MB) using <i>differentiable indirection</i> compared with uncompressd voxel representation (860 MB) trained using <i>Direct Voxel</i> technique.</p>
            <script src="https://cdn.knightlab.com/libs/juxtapose/latest/js/juxtapose.min.js"></script>
            <link rel="stylesheet" href="https://cdn.knightlab.com/libs/juxtapose/latest/css/juxtapose.css">
            <style>
                a.jx-knightlab div.knightlab-logo {
                    visibility: hidden;
                    display: none;
                }
                a.jx-knightlab span.juxtapose-name {
                    visibility: hidden;
                    display: none;
                }
                div.jx-slider {
                    color: #486fb6;
                }
            </style>

            <h2 id="download" class="content-subhead" style="margin-top: 20px;color:#001f3f;">Downloads</h2>
            <p>
                Paper: <a href="pdfs/din.pdf" style="text-decoration: none;">differentiableIndirection.pdf</a><br>
                Code: Coming Soon<br>
                Video description: <a href="https://drive.google.com/file/d/1UBwwjMsZKx2Fmx58p_IWIpYHWFVjsffq/view?usp=sharing" style="text-decoration: none;">HQ (MP4, 3.7GB)</a> || <a href="https://drive.google.com/file/d/1jrHfI2ErdHQFkZK3_LeH3LECcxyGhSYt/view?usp=sharing" style="text-decoration: none;">LQ (MP4, 500MB)</a> || <a href="bibs/din_caption.srt" style="text-decoration: none;">Captions</a><br>
                Bibtex: <a href="bibs/dinArxiv.bib" style="text-decoration: none;">arxiv.bib</a>
            </p>
            
            <h2 class="content-subhead" style="margin-top: 10px;color:#001f3f;">Acknowledgements</h2>
            <p style="text-align:justify;">We thank Cheng Chang, Sushant Kondguli, Anton Michels, Warren Hunt, and Abhinav Golas for their valuable input and the reviewers for their constructive feedback. We also thank Moshe Caine for the horse-model with <i>CC-BY-4.0</i> license, and <i>Adobe Substance-3D</i> for the <i>PBR</i> textures. This work was done when Sayantan was an intern at Meta Reality Labs Research. While at McGill University, he was also supported by a Ph.D. scholarship from the <i>Fonds de recherche du Québec -- nature et technologies.</i></p>
        </div>
    </div>
    <div class="pure-u-1 pure-u-md-1-4"></div>
</div>

<script src="js/ui.js"></script>

</body>
</html>
